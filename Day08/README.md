# День 08  — Machine Learning: Classification, Regression, Clustering

---

# Exercise 00 — Binary classifier

**Папка:** `ex00/`  
**Файл:** `00_binary_classifier_logreg.ipynb`  
**Разрешено:** без ограничений

### Описание

В этом упражнении необходимо обучить **первый бинарный классификатор**, который будет предсказывать:  
**коммит сделан в рабочий день или в выходной?**

### Требования

1. Использовать данные из предыдущих дней (таблица `checker`).
2. Выполнить **feature engineering**:
   - извлечь признак *количество коммитов до полудня*;
   - и *количество коммитов после полудня*.
3. Сформировать выборку:
   - **X** — два признака;
   - **y** — рабочий день / выходной.
4. Обучить логистическую регрессию (**LogisticRegression**).
5. Построить предсказания, вывести accuracy.
6. Визуализировать результаты.
7. Все подробные шаги — в ноутбуке.

---

# Exercise 01 — Decision boundaries

**Папка:** `ex01/`  
**Файл:** `01_binary_classifier_svm_tree.ipynb`  
**Разрешено:** без ограничений

### Описание

В этом упражнении нужно углубиться в интерпретацию моделей и границы решений (**decision boundaries**).

### Требования

1. Повторно обучить логистическую регрессию.
2. Обучить ещё два алгоритма:
   - **SVM** (линейный и/или RBF);
   - **Decision Tree Classifier**.
3. Визуализировать границы решений для всех трёх моделей.
4. Сравнить качество.
5. Все конкретные шаги расписаны внутри ноутбука.

---

# Exercise 02 — Multiclass classification

**Папка:** `ex02/`  
**Файл:** `02_multiclass_one-hot.ipynb`  
**Разрешено:** без ограничений

### Описание

Переход от бинарной классификации к **многоклассовой**.  

Также впервые используется **категориальное кодирование (one-hot)**.

### Требования

1. Цель — предсказывать **день недели** коммита (7 классов).
2. Использовать:
   - числовые признаки,
   - категориальные признаки (uid, labname),
   - one-hot encoding.
3. Обучить несколько моделей:
   - Logistic Regression (multinomial),
   - Decision Tree,
   - Random Forest.
4. Оценить качество.
5. Определить важность признаков.
6. Подробный план — в ноутбуке.

---

# Exercise 03 — Overfitting, train/test split & cross-validation

**Папка:** `ex03/`  
**Файл:** `03_split_crossval.ipynb`  
**Разрешено:** без ограничений

### Описание

Изучаем проблему **переобучения** и способы борьбы.

### Требования

1. Сделать **train/test split**.
2. Оценить качество модели на тесте.
3. Выполнить **cross-validation** (k-fold).
4. Сравнить результаты:
   - обучающая выборка,
   - тестовая,
   - среднее по CV.
5. Все шаги подробно расписаны в ноутбуке.

---

# Exercise 04 — Regression

**Папка:** `ex04/`  
**Файл:** `04_regression.ipynb`  
**Разрешено:** без ограничений

### Описание

Первая регрессия.  
Нужно предсказать:

**среднюю разницу между первым коммитом и дедлайном (avg_diff)**  
по данным о:
- количестве просмотров Newsfeed;
- количестве коммитов.

### Требования

1. Подготовить данные.
2. Обучить регрессионную модель:
   - Linear Regression или несколько моделей.
3. Посмотреть метрики качества (MAE, MSE, R²).
4. Визуализировать результаты.
5. Конкретика — внутри ноутбука.

---

# Exercise 05 — Clustering

**Папка:** `ex05/`  
**Файл:** `05_clustering.ipynb`  
**Разрешено:** без ограничений

### Описание

Используем **несупервайзинг** — кластеризацию.

Цель: определить группы пользователей по их поведению (коммиты, просмотры и т.д.).

### Требования

1. Подготовить признаки для кластеризации.
2. Обучить алгоритмы:
   - KMeans,
   - DBSCAN (опционально),
   - Agglomerative clustering (опционально).
3. Визуализировать кластеры.
4. Проанализировать поведение каждого кластера.
5. Все инструкции — прямо в ноутбуке.

---


